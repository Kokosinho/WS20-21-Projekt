import matplotlib.pyplot as plt
import os
import re
import shutil
import string
import tensorflow as tf

from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow.keras import preprocessing
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization

#print(tf.__version__)
dataset_dir = r'C:\Users\Leo\PycharmProjects\SemesterProjekt\venv\DATASET'

batch_size = 32
seed = 42

dataset = tf.keras.preprocessing.text_dataset_from_directory(
    dataset_dir, labels='inferred', label_mode='int',
    class_names=None, batch_size=batch_size, max_length=None, shuffle=True, seed=None,
    validation_split=None, subset=None, follow_links=False)

os.listdir(dataset_dir)

#creating training dataset
raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'Dataset',
    batch_size=batch_size,
    validation_split=0.2,
    subset='training',
    seed=seed)


#creating validation dataset
raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(
        'Dataset',
        batch_size=batch_size,
        validation_split=0.2,
        subset='validation',
        seed=seed)

raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'Dataset',
    batch_size=batch_size)


#Prepare Text for training
def custom_standardization(input_data):
    lowercase = tf.strings.lower(input_data)
    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')
    return tf.strings.regex_replace(stripped_html,
                                    '[%s]' % re.escape(string.punctuation),
                                    '')
max_features = 10000
sequence_length = 250

vectorize_layer = TextVectorization(
    standardize=custom_standardization,
    max_tokens=max_features,
    output_mode='int',
    output_sequence_length=sequence_length)

# Make a text-only dataset (without labels), then call adapt
train_text = raw_train_ds.map(lambda x, y: x)
vectorize_layer.adapt(train_text)

def vectorize_text(text, label):
  text = tf.expand_dims(text, -1)
  return vectorize_layer(text), label

# retrieve a batch (of 32 reviews and labels) from the dataset
text_batch, label_batch = next(iter(raw_train_ds))
first_Mail, first_label = text_batch[0], label_batch[0]
print("Mail", first_Mail)
print("Label", raw_train_ds.class_names[first_label])
print("Vectorized Mail", vectorize_text(first_Mail, first_label))

print("101 ---> ",vectorize_layer.get_vocabulary()[101])
print(" 55 ---> ",vectorize_layer.get_vocabulary()[55])
print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))

#apply TextVectorization Layer to train, test, and validation dataset
train_ds = raw_train_ds.map(vectorize_text)
val_ds = raw_val_ds.map(vectorize_text)
test_ds = raw_test_ds.map(vectorize_text)


#improve performance
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

#Creating the NN
embedding_dim = 16
model = tf.keras.Sequential([
  layers.Embedding(max_features + 1, embedding_dim),
  layers.Dropout(0.2),
  layers.GlobalAveragePooling1D(),
  layers.Dropout(0.2),
  layers.Dense(1)])

model.summary()

#loss function and optimizer
model.compile(loss=losses.BinaryCrossentropy(from_logits=True),
              optimizer='adam',
              metrics=tf.metrics.BinaryAccuracy(threshold=0.0))

#Training the model
epochs = 1000
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs)

#Evaluation
loss, accuracy = model.evaluate(test_ds)

print("Loss: ", loss)
print("Accuracy: ", accuracy)

history_dict = history.history
history_dict.keys()

acc = history_dict['binary_accuracy']
val_acc = history_dict['val_binary_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']

epochs = range(1, len(acc) + 1)

# "bo" is for "blue dot"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b is for "solid blue line"
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

plt.show()
